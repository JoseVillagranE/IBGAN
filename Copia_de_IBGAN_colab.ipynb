{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de IBGAN-colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "19oexAL-Fra7XBs804SmsnVkRwpW0MUKK",
      "authorship_tag": "ABX9TyOH+rNo4NdPkgSRi/cNut4r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoseVillagranE/IBGAN/blob/master/Copia_de_IBGAN_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CSIUavTem4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Parameter, init\n",
        "from torch.nn.utils import spectral_norm\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "from itertools import chain\n",
        "\n",
        "class UnFlatten(nn.Module):\n",
        "    \n",
        "    def __init__(self, block_size):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(x.size(0), -1, self.block_size, self.block_size)\n",
        "        \n",
        "class Flatten(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "class IBGAN(nn.Module):\n",
        "    \n",
        "    \n",
        "    def __init__(self, ngf, ndf, z_dim, r_dim, lr_G, lr_D, lr_Q, lr_E, nc=3, code_dim=0):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.r_dim = r_dim\n",
        "        \n",
        "        # Block programing with respect of paper\n",
        "        \n",
        "        self.Block_E = nn.Sequential(nn.Linear(z_dim, ngf*2), nn.BatchNorm1d(ngf*2), nn.ReLU(),\n",
        "                                     nn.Linear(ngf*2, ngf), nn.BatchNorm1d(ngf), nn.ReLU(),\n",
        "                                     nn.Linear(ngf, r_dim*2))\n",
        "        \n",
        "        self.Block_G = nn.Sequential(nn.Linear(r_dim+code_dim, ngf*16), nn.BatchNorm1d(ngf*16), nn.ReLU(),\n",
        "                                     nn.Linear(ngf*16, 64*4*ngf), nn.BatchNorm1d(64*4*ngf), nn.ReLU(),\n",
        "                                     UnFlatten(8),\n",
        "                                     nn.Conv2d(ngf*4, ngf*4, 3), nn.BatchNorm2d(ngf*4), nn.ReLU(),\n",
        "                                     nn.Conv2d(ngf*4, ngf*4, 3), nn.BatchNorm2d(ngf*4), nn.ReLU(),\n",
        "                                     nn.ConvTranspose2d(ngf*4, ngf*4, 4, 2, 1), nn.BatchNorm2d(ngf*4), nn.ReLU(),\n",
        "                                     nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1), nn.BatchNorm2d(ngf*2), nn.ReLU(),\n",
        "                                     nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1), nn.BatchNorm2d(ngf), nn.ReLU(),\n",
        "                                     nn.ConvTranspose2d(ngf, nc, 4, 2, 1), nn.Tanh())\n",
        "        \n",
        "        self.SubBlock_QD = nn.Sequential(nn.Conv2d(nc, ndf, 4, 2, 1), nn.ReLU(), # 31\n",
        "                                         nn.Conv2d(ndf, ndf*2, 4, 2, 1), nn.BatchNorm2d(ndf*2), nn.ReLU(), # 15\n",
        "                                         nn.Conv2d(ndf*2, ndf*4, 4, 2, 1), nn.BatchNorm2d(ndf*4), nn.ReLU(), # 7\n",
        "                                         #nn.Conv2d(ndf*4, ndf*4, 3, 1, 1), nn.BatchNorm2d(ndf*4), nn.ReLU(), # 5\n",
        "                                         #nn.Conv2d(ndf*4, ndf*4, 3, 1, 1), nn.BatchNorm2d(ndf*4), nn.ReLU(), # 3\n",
        "                                         spectral_norm(nn.Conv2d(ndf*4, ndf*16, 4, 1, 1)), nn.BatchNorm2d(16*ndf), nn.ReLU()) # 4\n",
        "       \n",
        "        self.Block_Q = nn.Sequential(Flatten(),\n",
        "                                     #nn.Linear(ndf*16*8, ndf*16), nn.BatchNorm1d(ndf*16), nn.ReLU(),\n",
        "                                     #nn.Linear(ndf*16*16,z_dim))\n",
        "                                     nn.Linear(50176, z_dim))\n",
        "                                     #nn.Linear(3211264, z_dim))\n",
        "        \n",
        "        self.Block_D = spectral_norm(nn.Conv2d(ndf*16, 1, 2, 1, 0))\n",
        "        \n",
        "        self.OptD = optim.RMSprop(chain(self.Block_D.parameters(), self.SubBlock_QD.parameters()), \n",
        "                                  lr=lr_D, momentum=0.9)\n",
        "        self.OptG = optim.RMSprop(self.Block_G.parameters(), lr=lr_G, momentum=0.9)\n",
        "        self.OptE = optim.RMSprop(self.Block_E.parameters(), lr=lr_E, momentum=0.9)\n",
        "        self.OptQ = optim.RMSprop(chain(self.Block_Q.parameters(), self.SubBlock_QD.parameters()), \n",
        "                                  lr=lr_Q, momentum=0.9)\n",
        "        \n",
        "    def r_sampler(self, x):\n",
        "        r = self.Block_E(x)\n",
        "        mu = r[:, :self.r_dim]\n",
        "        var = F.softplus(r[:, self.r_dim:]) + 1e-5\n",
        "        scale_tri = torch.diag_embed(var)\n",
        "        return MultivariateNormal(loc=mu, scale_tril=scale_tri)\n",
        "    \n",
        "    def generate(self, x):\n",
        "        g = self.Block_G(x)\n",
        "        return g\n",
        "        \n",
        "    def discriminate(self, x):\n",
        "        x = self.SubBlock_QD(x)\n",
        "        d = self.Block_D(x)\n",
        "        return d.view(-1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.SubBlock_QD(x)\n",
        "        Q = self.Block_Q(x)\n",
        "        D = self.Block_D(x)\n",
        "        return D.view(-1), Q"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWxNR8mrfAUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.distributions.kl import kl_divergence\n",
        "import torchvision.datasets as Dataset\n",
        "\n",
        "import tqdm\n",
        "from itertools import chain\n",
        "from os.path import join as pjoin\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import transforms\n",
        "import torch.utils.data as data\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "def InfiniteSampler(n):\n",
        "    # i = 0\n",
        "    i = n - 1\n",
        "    order = np.random.permutation(n)\n",
        "    while True:\n",
        "        yield order[i]\n",
        "        i += 1\n",
        "        if i >= n:\n",
        "            np.random.seed()\n",
        "            order = np.random.permutation(n)\n",
        "            i = 0\n",
        "\n",
        "\n",
        "class InfiniteSamplerWrapper(data.sampler.Sampler):\n",
        "    def __init__(self, data_source):\n",
        "        self.num_samples = len(data_source)\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(InfiniteSampler(self.num_samples))\n",
        "\n",
        "    def __len__(self):\n",
        "        return 2 ** 31\n",
        "\n",
        "\n",
        "def trans_maker(size=256):\n",
        "\ttrans = transforms.Compose([transforms.Resize((size)),\n",
        "\t\t\t\t\ttransforms.CenterCrop((size)), \n",
        "\t\t\t\t\ttransforms.ToTensor(),\n",
        "          transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5)),])\n",
        "\treturn trans\n",
        "\n",
        "def KL_Loss(z):\n",
        "\tmu = z.mean()\n",
        "\tlogvar = z.var().log()\n",
        "\treturn -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOAzjCqYDDgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('drive/My Drive/img_align_celeba.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./celeba_drive')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10bV7gE5nXi-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_dataset = './drive/My Drive/dataset'\n",
        "celeba_id = '0B7EVK8r0v71pZjFTYXZWM3FlRnM'"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z60g8HFv1rT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    def get_confirm_token(response):\n",
        "        for key, value in response.cookies.items():\n",
        "            if key.startswith('download_warning'):\n",
        "                return value\n",
        "\n",
        "        return None\n",
        "\n",
        "    def save_response_content(response, destination):\n",
        "        CHUNK_SIZE = 32768\n",
        "\n",
        "        with open(destination, \"wb\") as f:\n",
        "            for chunk in response.iter_content(CHUNK_SIZE):\n",
        "                if chunk: # filter out keep-alive new chunks\n",
        "                    f.write(chunk)\n",
        "\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)\n",
        "\n",
        "destination = '../celeba'\n",
        "download_file_from_google_drive(celeba_id, destination)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oCYY-4IzUL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def noise_sample(r_sample=None, n_dis_c=0, dis_c_dim=0, n_z=0, batch_size=0, device=None):\n",
        "    \"\"\"\n",
        "    Sample random noise vector for training w/ code if its needed.\n",
        "    INPUT\n",
        "    --------\n",
        "    r_sample : Sample of intermediate representation r for cat w/ code c.\n",
        "    n_dis_c : Number of discrete latent code.\n",
        "    dis_c_dim : Dimension of discrete latent code.\n",
        "    n_con_c : Number of continuous latent code.\n",
        "    n_z : Dimension of iicompressible noise.\n",
        "    batch_size : Batch Size\n",
        "    device : GPU/CPU\n",
        "    \"\"\"\n",
        "\n",
        "    idx = np.zeros((n_dis_c, batch_size))\n",
        "    if(n_dis_c != 0):\n",
        "        dis_c = torch.zeros(batch_size, n_dis_c, dis_c_dim, device=device)\n",
        "        \n",
        "        for i in range(n_dis_c):\n",
        "            idx[i] = np.random.randint(dis_c_dim, size=batch_size)\n",
        "            dis_c[torch.arange(0, batch_size), i, idx[i]] = 1.0\n",
        "\n",
        "        dis_c = dis_c.view(batch_size, -1)\n",
        "\n",
        "    if not r_sample==None:\n",
        "      noise = torch.cat((r_sample, dis_c), dim=1)\n",
        "    else:\n",
        "      noise = torch.randn(batch_size, n_z, device=device)\n",
        "      if(n_dis_c != 0):\n",
        "        noise = torch.cat((noise, dis_c), dim=1)\n",
        "\n",
        "    return noise, idx"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j3TEm6iffl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(Model, args_dict):\n",
        "    print('-'*25)\n",
        "    print('training')\n",
        "    print('-'*25)\n",
        "    #dataset = Dataset.ImageFolder(root=args_dict['DATA_ROOT'], transform=trans_maker(64)) \n",
        "    #subdataset = Subset(dataset, list(range(0, args_dict['NUM_IMG'])))\n",
        "    #dataloader = iter(DataLoader(subdataset, args_dict['BATCH_SIZE'], sampler=InfiniteSamplerWrapper(subdataset), num_workers=0, pin_memory=True))\n",
        "    \n",
        "    dataset = Dataset.CelebA(root=args_dict[\"DATA_ROOT\"], split=\"all\", transform=trans_maker(64), download=True)\n",
        "    #dataset = torch.load(path_to_dataset)\n",
        "    dataloader = DataLoader(dataset, args_dict['BATCH_SIZE'])\n",
        "    \n",
        "    loss_bce = nn.BCELoss()\n",
        "    loss_mse = nn.MSELoss()\n",
        "    \n",
        "    M_r = MultivariateNormal(loc=torch.zeros(args_dict['R_DIM']).to(args_dict['device']), \n",
        "    scale_tril=torch.ones(args_dict['R_DIM'], args_dict['R_DIM']).to(args_dict['device']))\n",
        "    \n",
        "    D_real = D_fake = D_z_kl = G_real = Z_recon = R_kl = 0\n",
        "    fixed_z = torch.randn(args_dict['BATCH_SIZE'], args_dict['Z_DIM']).to(args_dict['device'])\n",
        "    \n",
        "    LOG_INTERVAL = args_dict['LOG_INTERVAL']\n",
        "    \n",
        "    fixed_noise, _ = noise_sample(n_z=args_dict['Z_DIM'], batch_size=100, device=args_dict['device'])\n",
        "    D_loss = []\n",
        "    R_loss =[]\n",
        "    # for n_iter in tqdm.tqdm(range(0, args_dict['ITERATIONS'])):\n",
        "    \n",
        "    for epoch in range(args_dict['EPOCHS']):\n",
        "        Model = Model.train()\n",
        "        for n_iter, (X, _) in enumerate(dataloader):\n",
        "            # real_image = next(dataloader)[0].to(args_dict['device'])\n",
        "            real_image = Variable(X).to(args_dict['device'])\n",
        "            z, _ = noise_sample(n_z = args_dict['Z_DIM'], batch_size=args_dict['BATCH_SIZE'], device=args_dict['device'])\n",
        "            r_sampler = Model.r_sampler(z)\n",
        "\n",
        "            r_sample = r_sampler.sample()\n",
        "            c_and_r, _ = noise_sample(r_sample=r_sample, n_dis_c=args_dict['NUM_DIS_C'], dis_c_dim=args_dict['DIS_C_DIM'],\n",
        "                                  batch_size=args_dict['BATCH_SIZE'], device=args_dict['device'])\n",
        "            \n",
        "            \n",
        "            g_image = Model.generate(c_and_r)\n",
        "            \n",
        "            Model.OptD.zero_grad()\n",
        "            Model.OptQ.zero_grad()\n",
        "            pred_f = Model.discriminate(g_image.detach()) # Fake prediction\n",
        "            pred_r, rec_z = Model(real_image) # Real prediction and z tongo\n",
        "            d_loss = (loss_bce(torch.sigmoid(pred_f), torch.ones(pred_f.size()).to(args_dict['device'])) + \n",
        "                    loss_bce(torch.sigmoid(pred_r), torch.zeros(pred_r.size()).to(args_dict['device'])))\n",
        "            q_loss = KL_Loss(rec_z) # Assume a unit gaussian prior -> m(r)\n",
        "            #d_loss.backward()\n",
        "            total_loss = d_loss + q_loss\n",
        "            total_loss.backward()\n",
        "            Model.OptD.step()\n",
        "            Model.OptQ.step()\n",
        "    \n",
        "            D_real += torch.sigmoid(pred_r).mean().item()\n",
        "            D_fake += torch.sigmoid(pred_f).mean().item()\n",
        "            D_z_kl += q_loss.item()\n",
        "            \n",
        "            Model.OptG.zero_grad()\n",
        "            Model.OptE.zero_grad()\n",
        "            \n",
        "            pred_g, z_posterior = Model(g_image)\n",
        "            \n",
        "            g_loss = args_dict['LAMBDA_G']* loss_bce(torch.sigmoid(pred_g), torch.ones(pred_g.size()).to(args_dict['device']))\n",
        "            # reconstruction loss of z\n",
        "            recon_loss = loss_mse(z_posterior, z) # noise -> z_input\n",
        "            # kl loss between e(r|z) || m(r) as a variational inference\n",
        "            #kl_loss = BETA_KL * torch.distributions.kl.kl_divergence(r_likelihood, M_r).mean()\n",
        "            #kl_loss = args_dict['BETA_KL']*kl_divergence(r_sampler, M_r).mean()\n",
        "            kl_loss = args_dict['BETA_KL']*KL_Loss(r_sample)\n",
        "            total_loss = g_loss + recon_loss + kl_loss\n",
        "            total_loss.backward()\n",
        "            Model.OptE.step()\n",
        "            Model.OptG.step()\n",
        "    \n",
        "            # record the loss values\n",
        "            G_real += torch.sigmoid(pred_g).mean().item()\n",
        "            Z_recon += recon_loss.item()\n",
        "            R_kl += kl_loss.item()\n",
        "            \n",
        "\n",
        "\n",
        "        Model = Model.eval()\n",
        "        fixed_r_sample = Model.r_sampler(fixed_noise)\n",
        "        fixed_c_and_r, _ = noise_sample(r_sample=fixed_r_sample.sample(), n_dis_c=args_dict['NUM_DIS_C'], dis_c_dim=args_dict['DIS_C_DIM'],\n",
        "                                  batch_size=100, device=args_dict['device'])\n",
        "        gen_data = Model.generate(fixed_c_and_r).detach().cpu()\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(np.transpose(vutils.make_grid(gen_data, nrow=10, padding=2, normalize=True), (1,2,0)))\n",
        "        plt.show()\n",
        "        \n",
        "        #print(\"D(x): %.5f    D(G(z)): %.5f    D_kl: %.5f    G(z): %.5f    Z_rec: %.5f    R_kl: %.5f\"% (D_real/LOG_INTERVAL, D_fake/LOG_INTERVAL, D_z_kl/LOG_INTERVAL, G_real/LOG_INTERVAL, Z_recon/LOG_INTERVAL, R_kl/LOG_INTERVAL))\n",
        "        D_l = D_z_kl/args_dict['BATCH_SIZE']\n",
        "        R_l = R_kl/args_dict['BATCH_SIZE']\n",
        "        D_loss.append(D_l)\n",
        "        R_loss.append(R_l)\n",
        "        print(\"D_l: {} | R_l: {} | Epoch: {}\".format(D_l, R_l, epoch))\n",
        "        D_real = D_fake = D_z_kl = G_real = Z_recon = R_kl = 0\n",
        "            \n",
        "    return D_loss, R_loss"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGA5Pa-Yfv-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "b68c3594-119c-4c2a-dc74-b7f6f2f1e08a"
      },
      "source": [
        "import random\n",
        "seed = 1100\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "Z_DIM = 500\n",
        "R_DIM = 15\n",
        "NDF = 64\n",
        "NGF = 64\n",
        "EPOCHS = 100\n",
        "LOG_INTERVAL = 1\n",
        "NUM_IMG = 1500\n",
        "LAMBDA_G = 1\n",
        "BETA_KL = 0.3\n",
        "DATA_ROOT = \"./celeba_drive/\"\n",
        "device = \"cuda:0\" if torch.cuda.is_available else \"cpu\"\n",
        "\n",
        "num_dis_c = 10\n",
        "dis_c_dim = 10\n",
        "\n",
        "args_dict = {\"BATCH_SIZE\": BATCH_SIZE, \"Z_DIM\": Z_DIM, \"R_DIM\": R_DIM, \"NDF\": NDF, \"NGF\": NGF, \"EPOCHS\": EPOCHS, \n",
        "          \"LAMBDA_G\": LAMBDA_G, \"BETA_KL\": BETA_KL, \"device\": device, \"DATA_ROOT\": DATA_ROOT, \"LOG_INTERVAL\": LOG_INTERVAL,\n",
        "          \"NUM_IMG\": NUM_IMG, \"NUM_DIS_C\": num_dis_c, \"DIS_C_DIM\": dis_c_dim}\n",
        "    \n",
        "lr = 1e-5\n",
        "lr_D = 1e-7\n",
        "IBGAN_model = IBGAN(NGF, NDF, Z_DIM, R_DIM, lr, lr_D, lr, lr, code_dim=num_dis_c*dis_c_dim)\n",
        "IBGAN_model = IBGAN_model.to(device)\n",
        "\n",
        "train(IBGAN_model, args_dict)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-57eefb5dbc39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdgC0CQWaQVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}